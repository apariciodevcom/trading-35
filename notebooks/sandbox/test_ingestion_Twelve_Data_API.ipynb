{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf4d35c-31e7-4ded-9e8c-a637e995cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key cargada: 0428b2...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"D:/trading/.env\")\n",
    "\n",
    "api_key = os.getenv(\"TWELVE_API_KEY\")\n",
    "print(\"API Key cargada:\", api_key[:6] + \"...\" if api_key else \"No cargada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d552e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Carpeta D:\\trading\\data\\historic limpiada y recreada.\n",
      "🧹 Carpeta limpia: D:\\trading\\data\\historic_reciente\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === CARGAR VARIABLES DESDE .env ===\n",
    "load_dotenv(\"D:/trading/.env\")\n",
    "API_KEY = os.getenv(\"TWELVE_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"⚠️ No se pudo cargar la API key. Verificá el archivo .env\")\n",
    "\n",
    "# === CONFIGURACIÓN LOCAL ===\n",
    "CONFIG_PATH = Path(\"D:/trading/config/symbol_groups.json\")\n",
    "\n",
    "# === Carpetas de salida ===\n",
    "OUTPUT_DIR = Path(\"D:/trading/data/historic\")\n",
    "OUTPUT_RECENT_DIR = Path(\"D:/trading/data/historic_reciente\")\n",
    "\n",
    "# === LIMPIAR CARPETA DE SALIDA ===\n",
    "if OUTPUT_DIR.exists():\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Carpeta {OUTPUT_DIR} limpiada y recreada.\")\n",
    "\n",
    "# Limpiar carpeta de históricos recientes\n",
    "if OUTPUT_RECENT_DIR.exists():\n",
    "    shutil.rmtree(OUTPUT_RECENT_DIR)\n",
    "OUTPUT_RECENT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"🧹 Carpeta limpia: {OUTPUT_RECENT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee66657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# === LECTURA DE SIMBOLOS ===\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    grupos = json.load(f)\n",
    "\n",
    "# === RATE LIMITER ===\n",
    "class APIRateLimiter:\n",
    "    def __init__(self, max_requests=5, window_seconds=60):\n",
    "        self.max_requests = max_requests\n",
    "        self.window_seconds = window_seconds\n",
    "        self.timestamps = deque()\n",
    "\n",
    "    def wait_if_needed(self):\n",
    "        now = time.time()\n",
    "        while self.timestamps and now - self.timestamps[0] > self.window_seconds:\n",
    "            self.timestamps.popleft()\n",
    "        if len(self.timestamps) >= self.max_requests:\n",
    "            sleep_time = self.window_seconds - (now - self.timestamps[0]) + 0.5\n",
    "            print(f\"Esperando {sleep_time:.1f}s por rate limit...\")\n",
    "            time.sleep(sleep_time)\n",
    "        self.timestamps.append(time.time())\n",
    "\n",
    "rate_limiter = APIRateLimiter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082190ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(symbol):\n",
    "    rate_limiter.wait_if_needed()\n",
    "    \n",
    "    url = \"https://api.twelvedata.com/time_series\"\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": \"1day\",\n",
    "        \"outputsize\": 5000,\n",
    "        \"apikey\": API_KEY,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"values\" not in data:\n",
    "        raise ValueError(f\"No data for {symbol}: {data.get('message', data)}\")\n",
    "    \n",
    "    df = pd.DataFrame(data[\"values\"])\n",
    "    numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    df = df.sort_values(\"datetime\")\n",
    "    return df\n",
    "\n",
    "def guardar_parquet(df, symbol):\n",
    "    path = OUTPUT_DIR / f\"{symbol}.parquet\"\n",
    "    df.to_parquet(path, index=False, compression=\"snappy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7663b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Procesando grupo_1 (3 simbolos) ==\n",
      "SMCI: OK\n",
      "AAPL: OK\n",
      "XOM: OK\n",
      "\n",
      "Finalizado: 3 OK, 0 con error.\n"
     ]
    }
   ],
   "source": [
    "total_ok = 0\n",
    "total_error = 0\n",
    "\n",
    "for grupo, simbolos in grupos.items():\n",
    "    print(f\"\\n== Procesando {grupo} ({len(simbolos)} simbolos) ==\")\n",
    "    for i, symbol in enumerate(simbolos):\n",
    "        try:\n",
    "            df = fetch_data(symbol)\n",
    "            guardar_parquet(df, symbol)\n",
    "            print(f\"{symbol}: OK\")\n",
    "            total_ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"{symbol}: ERROR - {e}\")\n",
    "            total_error += 1\n",
    "        if i < len(simbolos) - 1:\n",
    "            time.sleep(11)\n",
    "\n",
    "print(f\"\\nFinalizado: {total_ok} OK, {total_error} con error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467c7346-99ed-41bd-8915-ae3c759340a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AAPL.parquet: actualizado y recorte generado.\n",
      "✅ SMCI.parquet: actualizado y recorte generado.\n",
      "✅ XOM.parquet: actualizado y recorte generado.\n"
     ]
    }
   ],
   "source": [
    "for archivo in OUTPUT_DIR.glob(\"*.parquet\"):\n",
    "    try:\n",
    "        df = pd.read_parquet(archivo)\n",
    "\n",
    "        # Convertir datetime → fecha si es necesario\n",
    "        if \"fecha\" not in df.columns:\n",
    "            if \"datetime\" in df.columns:\n",
    "                df[\"fecha\"] = pd.to_datetime(df[\"datetime\"])\n",
    "                df.drop(columns=[\"datetime\"], inplace=True)\n",
    "            else:\n",
    "                print(f\"⚠️ {archivo.name} no tiene ni 'fecha' ni 'datetime'. Saltado.\")\n",
    "                continue\n",
    "\n",
    "        # Ordenar y limpiar duplicados\n",
    "        df = df.sort_values(\"fecha\").drop_duplicates(\"fecha\")\n",
    "\n",
    "        # Reescribir archivo completo (ordenado y limpio)\n",
    "        df.to_parquet(archivo, index=False)\n",
    "\n",
    "        # Crear y guardar recorte\n",
    "        df_recent = df.tail(60)\n",
    "        recent_path = OUTPUT_RECENT_DIR / archivo.name\n",
    "        df_recent.to_parquet(recent_path, index=False)\n",
    "\n",
    "        print(f\"✅ {archivo.name}: actualizado y recorte generado.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error procesando {archivo.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88595e-0512-49ba-af64-faf3e0460983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
